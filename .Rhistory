dat
dat=read.csv("C:/Users/Administrator/Desktop/建模/第四节课：多元统计/程序/examp8.4.2.csv")
dat
row.names(dat)=dat[,1]
View(dat)
View(dat)
row.names(dat)=dat[,1]
dat
student=dist(dat[2:9])
student=dist(dat[2:9])
dat
head(dat)
student=dist(dat[4:9])
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
summary(student.pr,loadings=T)  #输出载荷loadings=T
student=dist(dat[4:9])
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
student<-data.frame(
X1=c(148, 139, 160, 149, 159, 142, 153, 150, 151, 139,
140, 161, 158, 140, 137, 152, 149, 145, 160, 156,
151, 147, 157, 147, 157, 151, 144, 141, 139, 148),
X2=c(41, 34, 49, 36, 45, 31, 43, 43, 42, 31,
29, 47, 49, 33, 31, 35, 47, 35, 47, 44,
42, 38, 39, 30, 48, 36, 36, 30, 32, 38),
X3=c(72, 71, 77, 67, 80, 66, 76, 77, 77, 68,
64, 78, 78, 67, 66, 73, 82, 70, 74, 78,
73, 73, 68, 65, 80, 74, 68, 67, 68, 70),
X4=c(78, 76, 86, 79, 86, 76, 83, 79, 80, 74,
74, 84, 83, 77, 73, 79, 79, 77, 87, 85,
82, 78, 80, 75, 88, 80, 76, 76, 73, 78))
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
row.names(dat)=dat[,1]
head(dat)
student=dist(dat[4:9])
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
summary(student.pr,loadings=T)  #输出载荷loadings=T
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
student.pr
row.names(dat)=dat[,1]
head(dat)
student=dist(dat[4:9])
row.names(dat)=dat[,1]
head(dat)
cor(m1)   #计算相关系数矩阵
View(dat)
View(dat)
View(dat)
View(dat)
cor(m1)   #计算相关系数矩阵
install.packages("psych")
install.packages("psych")
library(psych)  #检验相关系数是不是对角阵。 如果不相关，则无法进行分析。
cortest.bartlett(cor(m1),n=18)
factanal(m1,factors=3)   #利用factanal进行因子分析
fal=factanal(~., factors = 3,scores = "Bartlett")
fal=factanal(Specieal~., factors = 3,scores = "Bartlett")
factanal(m1,factors=3)   #利用factanal进行因子分析
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
fal=factanal(~v1+v2+v3+v4+v5+v6, factors = 3,scores = "Bartlett")
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
?factanal
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
fal$scores #输出因子得分
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
fal$scores #输出因子得分
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
m1=dat[4:9]
m1
View(m1)
View(m1)
m1=dat[3:10]
m1
View(m1)
View(m1)
m1=dat[3:12]
m1
View(m1)
View(m1)
cor(m1)   #计算相关系数矩阵
library(psych)  #检验相关系数是不是对角阵。 如果不相关，则无法进行分析。
cortest.bartlett(cor(m1),n=18)
?cortest.bartlett
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
View(m1)
fal$scores #输出因子得分
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
?factanal
v1 <- c(1,1,1,1,1,1,1,1,1,1,3,3,3,3,3,4,5,6)
v2 <- c(1,2,1,1,1,1,2,1,2,1,3,4,3,3,3,4,6,5)
v3 <- c(3,3,3,3,3,1,1,1,1,1,1,1,1,1,1,5,4,6)
v4 <- c(3,3,4,3,3,1,1,2,1,1,1,1,2,1,1,5,6,4)
v5 <- c(1,1,1,1,1,3,3,3,3,3,1,1,1,1,1,6,4,5)
v6 <- c(1,1,1,2,1,3,3,3,4,3,1,1,1,2,1,6,5,4)
m1 <- cbind(v1,v2,v3,v4,v5,v6)  #按列合
cor(m1)   #计算相关系数矩阵
cortest.bartlett(cor(m1),n=18)
?factanal
factanal(m1,factors=3)   #利用factanal进行因子分析
factanal(m1,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
factanal(m1,factors=3)   #利用factanal进行因子分析
fal=factanal(~v1+v2+v3+v4+v5+v6, factors = 3,scores = "Bartlett")
fal$scores #输出因子得分
factanal(m1,factors=3)   #利用factanal进行因子分析
factanal(m1,factors=3)
factanal(m1,factors=4)
cortest.bartlett(cor(m2))
row.names(dat)=dat[,1]
head(dat)
m2=dat[3:12]
m2
cor(m2)   #计算相关系数矩阵
#install.packages("psych")
library(psych)  #检验相关系数是不是对角阵。 如果不相关，则无法进行分析。
cortest.bartlett(cor(m2))
?factanal
factanal(m1,factors=4)
factanal(m2,factors=4)
factanal(m2,factors=3)
factanal(m2,factors=3,scores = "Bartlett")   #利用factanal进行因子分析
View(m2)
View(m2)
row.names(dat)=dat[,1]
row.names(dat)=dat[,1]
head(dat)
library(psych)  #检验相关系数是不是对角阵。 如果不相关，则无法进行分析。
cortest.bartlett(cor(m2))
?factanal
factanal(m2,factors=3)
factanal(m2,factors=6)
factanal(m2,factors=5)
factanal(m2,factors=5,scores = "Bartlett")   #利用factanal进行因子分析
fal$scores #输出因子得分
row.names(dat)=dat[,1]
head(dat)
student=dat[3:12]
View(student)
View(student)
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
student.pr
summary(student.pr,loadings=T)  #输出载荷loadings=T
cortest.bartlett(cor(m2))
student.pr<-princomp(student, cor=T)   #利用princomp()进行主成分分析
student.pr
summary(student.pr,loadings=T)  #输出载荷loadings=T
cortest.bartlett(cor(m2),18)
?cortest.bartlett
dat=read.table("D:/R/我的资料集/自学/多元统计/数据/4、数据.txt",header=T)
read.csv("C:/Users/Administrator/Desktop/建模/第四节课：聚类判别因子主成分/程序/数据examp8.4.2.csv")
read.csv("D:/R/我的资料集/自学/多元统计/数据/examp8.4.2.csv")
dat
View(dat)
View(dat)
dreg=dist(dat[3:12])  #函数dist()用来定义样品之间的距离
View(dat)
dat
View(dat)
dreg=dist(dat[2:9])  #函数dist()用来定义样品之间的距离
dhc1=hclust(dreg,"single")
dhc2=hclust(dreg,"centroid")
dhc3=hclust(dreg,"ward")
plot(dhc1)
rect.hclust(dhc1,k=5)
windows()
plot(dhc2)
rect.hclust(dhc2,k=5)
windows()
?hclust()
library(MASS)
data(iris)
lda1 <- lda(Species~.,data=iris)
lda1
iris.pred=predict(lda1)
table(iris$Species,iris.pred$class)
plot(iris.pred$x)
points(iris.pred$x[1:50,])
points(iris.pred$x[51:100,],col=2)
points(iris.pred$x[101:150,],col=3)
lda1
lda1
p
summary(p)
p <- ggplot(diamonds, aes(x = carat))
p <- p + layer(
geom = "bar",
geom_params = list(fill = "steelblue"),
stat = "bin",
stat_params = list(binwidth = 2)
)
summary(p)
layer(geom, geom_params, stat, stat_params, data, mapping,position)
p <- ggplot(diamonds, aes(x = carat))
library(ggplot2)
p <- ggplot(diamonds, aes(x = carat))
p <- p + layer(
geom = "bar",
geom_params = list(fill = "steelblue"),
stat = "bin",
stat_params = list(binwidth = 2)
)
summary(p)
p
p <- ggplot(diamonds, aes(x = carat))
p <- p + layer(
geom = "bar",
geom_params = list(fill = "steelblue"),
stat = "bin",
stat_params = list(binwidth = 2)
)
summary(p)
p
qplot(sleep_rem / sleep_total, awake, data = msleep)
ggplot(msleep, aes(sleep_rem / sleep_total, awake)) +geom_point()
qplot(sleep_rem / sleep_total, awake, data = msleep,geom = c("point", "smooth"))
ggplot(msleep, aes(sleep_rem / sleep_total, awake)) +geom_point() + geom_smooth()
library(XML)
library(RCurl)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc <-htmlParse(wp, asText= TRUE)
tables <-readHTMLTable(doc)
tables
doc<-htmlParse(wp, asText= TRUE)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc<-htmlParse(wp, asText= TRUE)
doc<-htmlParse(wp, asText=TRUE)
doc<-htmlParse(wp,asText=TRUE)
?htmlParse
doc<-htmlTreeParse(wp,asText=TRUE)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc <-htmlParse(wp, asText= TRUE)
tables <-readHTMLTable(doc,header=F)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc <-htmlParse(wp, asText= TRUE)
tables <-readHTMLTable(doc,which=5)
library(XML)
library(RCurl)
temp<-getURL(url)
url="http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1"
temp<-getURL(url)
temp
temp
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc<-htmlParse(wp, asText= TRUE)
tables<-readHTMLTable(doc)
library(RCurl)
library(XML)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc<-htmlParse(wp, asText= TRUE)
tables<-readHTMLTable(doc)
tables
library(RCurl)
library(XML)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc<-htmlParse(wp, asText= TRUE)
tables<-readHTMLTable(doc)
tables
tables
named list()
library(RCurl)
library(XML)
url="http://www.bioguo.org/AnimalTFDB/BrowseAllTF.php?spe=Mus_musculus"
wp<-getURL(url)
doc<-htmlParse(wp, asText= TRUE)
tables<-readHTMLTable(doc)
tables
url="http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1"
wp<-getURL(url)
wp
library(RCurl)
library(XML)
url="http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1"
wp1<-getURL(url)
wp1
wp1<-getURL(url,httpheader=myheader)
myheader<-c(
"User-Agent"="Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.6) ",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="en-us",
"Connection"="keep-alive",
"Accept-Charset"="GB2312,utf-8;q=0.7,*;q=0.7")
url="http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1"
wp1<-getURL(url,httpheader=myheader)
wp1
wp1<-getURL("http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1",httpheader=myheader)
wp1
myheader<-c(
"User-Agent"="Mozilla/5.0 (Windows; U; Windows NT 5.1; zh-CN; rv:1.9.1.6) ",
"Accept"="text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
"Accept-Language"="en-us",
"Connection"="keep-alive",
"Accept-Charset"="GB2312,utf-8;q=0.7,*;q=0.7")
wp1<-getURL("http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1",httpheader=myheader)
temp<-getURL("http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1",httpheader=myheader)
temp<-getURL("http://www.w3school.com.cn/example/xmle/books.xml",httpheader=myheader)
temp
temp<-getURL("http://t.dianping.com/guangzhou?q=%E7%94%B5%E5%BD%B1",httpheader=myheader)
temp
install.packages("RSNNS")
library(RSNNS)
data(iris)
iris = iris[sample(1:nrow(iris),length(1:nrow(iris))),1:ncol(iris)]
irisValues= iris[,1:4]
irisTargets = decodeClassLabels(iris[,5])
iris = splitForTrainingAndTest(irisValues, irisTargets, ratio=0.15)
iris = normTrainingAndTestSet(iris)
model = mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFunc="Quickprop", learnFuncParams=c(0.1, 2.0, 0.0001, 0.1),maxit=100, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)
predictions = predict(model,iris$inputsTest)
confusionMatrix(iris$targetsTest,predictions)
View(irisValues)
View(irisValues)
View(irisValues)
View(irisValues)
model = mlp(iris$inputsTrain, iris$targetsTrain, size=5, learnFunc="Quickprop", learnFuncParams=c(0.1, 2.0, 0.0001, 0.1),maxit=100, inputsTest=iris$inputsTest, targetsTest=iris$targetsTest)
predictions = predict(model,iris$inputsTest)
confusionMatrix(iris$targetsTest,predictions)
a<-0.2
w<-rep(0,3)
iris1<-t(as.matrix(iris[,3:4]))
d<-c(rep(0,50),rep(1,100))
e<-rep(0,150)
p<-rbind(rep(1,150),iris1)
max<-100000
eps<-rep(0,100000)
i<-0
repeat{
v<-w%*%p;
y<-ifelse(sign(v)>=0,1,0);
e<-d-y;
eps[i+1]<-sum(abs(e))/length(e)
if(eps[i+1]<0.01){
print("finish:");
print(w);
break;
}
w<-w+a*(d-y)%*%t(p);
i<-i+1;
if(i>max){
print("max time loop");
print(eps[i])
print(y);
break;
}
}
library(RSNNS)
data(iris)
a<-0.2
w<-rep(0,3)
iris1<-t(as.matrix(iris[,3:4]))
d<-c(rep(0,50),rep(1,100))
e<-rep(0,150)
p<-rbind(rep(1,150),iris1)
max<-100000
eps<-rep(0,100000)
i<-0
repeat{
v<-w%*%p;
y<-ifelse(sign(v)>=0,1,0);
e<-d-y;
eps[i+1]<-sum(abs(e))/length(e)
if(eps[i+1]<0.01){
print("finish:");
print(w);
break;
}
w<-w+a*(d-y)%*%t(p);
i<-i+1;
if(i>max){
print("max time loop");
print(eps[i])
print(y);
break;
}
}
plot(Petal.Length~Petal.Width,xlim=c(0,3),ylim=c(0,8),
data=iris[iris$Species=="virginica",])
data1<-iris[iris$Species=="versicolor",]
points(data1$Petal.Width,data1$Petal.Length,col=2)
data2<-iris[iris$Species=="setosa",]
points(data2$Petal.Width,data2$Petal.Length,col=3)
x<-seq(0,3,0.01)
y<-x*(-w[2]/w[3])-w[1]/w[3]
lines(x,y,col=4)
#绘制每次迭代的平均绝对误差
plot(1:i,eps[1:i],type="o")
?abline
library(DMwR)
head(algae)
summary(algae)
hist(algae$mxPH, prob=T)  #百分比形式输出
hist(algae$size , prob=T,main='size ',ylim=0:1)
hist(algae$mnO2 , prob=T,main='mnO2',ylim=0:1)
lines(density(algae$mnO2 ,na.rm = T))
rug(jitter(algae$size ))
rug(jitter(algae$mnO2))
qq.plot(algae$mxPH,main='Normal QQ plot of maximum pH')
qqplot(algae$mxPH,main='Normal QQ plot of maximum pH')
qqplot(algae$mnO2,main='Normal QQ plot of maximum pH')
qq.plot(algae$mnO2,main='Normal QQ plot of maximum pH')
qq.plot(algae$mxPH,main='Normal QQ plot of maximum pH')
boxplot(algae$oPO4,boxwex=0.15,ylab='Orthophosphate (oPO4)')
rug(jitter(algae$oPO4),side=2)
abline(h=mean(algae$oPO4,na.rm=T),lty=2)
library(lattice)
bwplot(size ~ a1, data=algae,ylab=’River Size’,xlab=’Alga A1’)
install.packages("lattice")
install.packages("lattice")
install.packages("lattice")
library(lattice)
bwplot(size ~ a1, data=algae,ylab='River Size',xlab='Alga A1')
head(algae)
library(DMwR)
head(algae)
summary(algae)
library(lattice)
bwplot(size ~ a1, data=algae,ylab='River Size',xlab='Alga A1')
algae[!complete.cases(algae),]
nrow(algae[!complete.cases(algae),])
algae <- na.omit(algae)
View(algae)
View(algae)
algae[48,’mxPH’] <- mean(algae$mxPH,na.rm=T)
algae[48,'mxPH'] <- mean(algae$mxPH,na.rm=T)
algae
algae[48]
data(algae)
algae[48,'mxPH'] <- mean(algae$mxPH,na.rm=T)
algae
head(algae)
algae
algae <- algae[-c(62,199),]  #数据清理
clean.algae <- algae
lm.a1<-lm(a1~ ., data=clean.algae[,1:12])
summary(lm.a1)
library(DMwR)
head(algae)
summary(algae)
###数据分析和可视化###
hist(algae$mxPH, prob=T)  #百分比形式输出
library(car)
#画直方图，，观看数据分布
par(mfrow=c(1,2))
lines(density(algae$mxPH,na.rm = T))
hist(algae$mxPH, prob=T,main='Histogram of maximum pH value',ylim=0:1)
rug(jitter(algae$mxPH))
qq.plot(algae$mxPH,main='Normal QQ plot of maximum pH')
par(mfrow=c(1,1))
#画箱线图观看数据分布以及离群值的多少
rug(jitter(algae$oPO4),side=2)
boxplot(algae$oPO4,boxwex=0.15,ylab='Orthophosphate (oPO4)')
abline(h=mean(algae$oPO4,na.rm=T),lty=2)
#观看离群值
plot(algae$NH4,xlab='')
abline(h=mean(algae$NH4,na.rm=T)+sd(algae$NH4,na.rm=T),lty=2)
abline(h=mean(algae$NH4,na.rm=T),lty=1)
abline(h=median(algae$NH4,na.rm=T),lty=3)
#identify(algae$NH4)  #交互式，点单击点的行号。会有交互
#观察a1变量如何依赖与其他变量
#install.packages("lattice")
library(lattice)
bwplot(size ~ a1, data=algae,ylab='River Size',xlab='Alga A1')
###数据缺失###
#方法
#•  Remove the cases with unknowns
#•  Fill in the unknown values by exploring the correlations between variables
#•  Fill in the unknown values by exploring the similarity between cases
#•  Use tools that are able to handle these values.
algae[!complete.cases(algae),]   #显示各行缺失值
nrow(algae[!complete.cases(algae),])
algae <- na.omit(algae)
algae <- algae[-c(62,199),]  #删除缺失值的行
#Filling in the unknowns with the most frequent values
algae[48,'mxPH'] <- mean(algae$mxPH,na.rm=T)  #用列平均值代替缺失值
###获取预测模型
algae <- algae[-c(62,199),]  #数据清理
clean.algae <- algae
lm.a1<-lm(a1~ ., data=clean.algae[,1:12])  #线性回归模型
summary(lm.a1)
plot(lm.a1)
help(step)
demo(graphics)
citation(package=’package’)
help.start
getwd()
data()
data(Loblolly)
data$Loblolly
data()$Loblolly
1.2E-10
data(CO2)
sink("CO2.txt")
CO2
sink() # g o t o y o u r wo r k d i r e c t o r y , y o u w i l l g e t CO2 . t x t
data(CO2)
sink("CO2.txt")
CO2
sink() # g o t o y o u r wo r k d i r e c t o r y , y o u w i l l g e t CO2 . t x t
data(CO3)
sink("CO3.txt")
setwd(D:/R/我的资料集)
setwd("D:/R/我的资料集")
read,table("clipboard")
read.table("clipboard")
read.table("clipboard")
data<-read.table("clipboard")
